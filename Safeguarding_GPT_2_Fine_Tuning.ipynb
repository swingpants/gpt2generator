{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Safeguarding_GPT_2_Fine_Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# Fine Tuning GPT-2 for Safeguarding text generation.\n",
        "---\n",
        "\n",
        "Looking to fine-tune GPT2 in order to generate synthetic safeguarding data that would otherwise be difficult to source. The context is for a custom keyboard - so the classifier would be looking at short messages being written by a user to send on a messaging/social media platofrm. The messages will be short - one or two sentences. \n",
        "\n",
        "This Notebook is based on work by Richard Bownes who described fine-tuning to generate text int he style of the card game Magic The Gathering. https://medium.com/swlh/fine-tuning-gpt-2-for-magic-the-gathering-flavour-text-generation-3bafd0f9bb93\n",
        "\n",
        "This Notebook uses [PyTorch](https://pytorch.org/) and Transformers from [Hugging Face](https://huggingface.co/) to fine tune a [GPT-2 Model](https://openai.com/blog/gpt-2-1-5b-release/) that will generate messages based on a small set of example messages\n",
        "\n",
        "\n",
        "This Notebook only slightly varies from Richard's one, all credit to him.\n",
        "---\n",
        "\n",
        " Here are his credits:\n",
        "\n",
        "\n",
        "I've borrowed heavily from those who came before me for inspiration and code chunks for this notebook, please check out [Rey Farhan](http://reyfarhan.com/posts/easy-gpt2-finetuning-huggingface/), who in turn heavily cites [Chris McCormick's](https://mccormickml.com/2019/07/22/BERT-fine-tuning/) BERT fine-tuning tutorial, [Ian Porter's](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html) GPT2 tutorial and the [Hugging Face](https://huggingface.co/transformers/v2.0.0/examples.html#language-model-fine-tuning) Language model fine-tuning script.\n",
        "\n",
        "By the end of this tutorial you should be able to quickly and easily fine tune your own language model for generative tasks and have a decent understanding of the levers you can adjust to parameterize the model!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf3Qw77SZGbS"
      },
      "source": [
        "# Setup\n",
        "\n",
        "We will be fine tuning an existing GPT2 model using the interface Hugging Face provides. Fine tuning instead of retraining for a few very simple and pragmatic reasons. First among them these language models requre vast swaths of data and are computationally prohibitively expensive to train. However, by leveraging what is already available we can cut out both of these requirements. This means we can tweak the outputs of the model to suit specific purposes with minimal data and with achievable hardward. This is essentially transfer learning for language generation problems. To start off with we need to install the Huggingface transformers library first. Many of the common scientific libraries are pre-installed on Colab but not this one in particular. Installing transformers will also install tokenizers, a dependency, and another useful set of tools for this task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdCML6Parvv"
      },
      "source": [
        "# Create Training Set\n",
        "\n",
        "We're going to use the flavor text of existing MTG cards to generate new ones. Luckily, the hard work of scraping the data has been done for us and we can ingest the flavor text from the [Scryfall](https://scryfall.com/advanced) API and quickly parson the json we are returned. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-MYTjAIxfBr",
        "outputId": "045954df-20f2-4018-c55e-6beaab7e11be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# We'll need these libraries to gather and shape the data.\n",
        "import requests \n",
        "import pandas as pd\n",
        "from itertools import compress\n",
        "\n",
        "# This will return the data for all the cards available to scryfall.\n",
        "r = requests.get('https://raw.githubusercontent.com/swingpants/gpt2generator/main/Suicide_Data_BBC_Generated.json')\n",
        "data = r.json()\n",
        "\n",
        "# we'll start parsing by removing any cards with no flavor text\n",
        "#contains_x = []\n",
        "#for i in data:\n",
        "    #print (i['message'])\n",
        "\n",
        "    #contains_x.append('message' in i.keys())\n",
        "\n",
        "#data_filtered = list(compress(data, contains_x))\n",
        "\n",
        "# next we'll remove any cards in a language other than english\n",
        "#contains_y = []\n",
        "#for i in data_filtered:\n",
        "#  contains_y.append('lang' in i.keys() and 'en' == i['lang'])\n",
        "\n",
        "#data_filtered = list(compress(data_filtered, contains_y))\n",
        "\n",
        "# Now we'll create a list to iterate through.\n",
        "cardValues = []\n",
        "for i in data:\n",
        "    cardValues.append(i['message'])\n",
        "\n",
        "# I'll convert this to a data frame to visualize a few rows nicely\n",
        "# mostly just a sanity check.\n",
        "df = pd.DataFrame(\n",
        "    cardValues,\n",
        "    columns=['data']\n",
        "    )\n",
        "\n",
        "cards = df.data.copy()\n",
        "cards"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                   it was a cry for help\n",
              "1                              A friend attempted suicide\n",
              "2                              A relative died by suicide\n",
              "3                            My teacher attempted suicide\n",
              "4                 i know someone who has comitted suicide\n",
              "                              ...                        \n",
              "1081    i'm so upset about the way things are, i want ...\n",
              "1082                     it was my way of killing myself.\n",
              "1083    don't want to be alive again, no longer want t...\n",
              "1084            I feel like a child again, i want to die.\n",
              "1085               why am i thinking about killing myself\n",
              "Name: data, Length: 1086, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMml12FJGjPW"
      },
      "source": [
        "# GPT2 Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANJhbBwdxN-b"
      },
      "source": [
        "First a brief description of tokenization straight from the source, the Hugging Face [Tokenizers](https://github.com/huggingface/tokenizers) github page:\n",
        "\n",
        "```\n",
        "What is a Tokenizer\n",
        "\n",
        "A Tokenizer works as a pipeline, it processes some raw text as input and outputs an Encoding. The various steps of the pipeline are:\n",
        "\n",
        "- The Normalizer: in charge of normalizing the text. Common examples of normalization are the unicode normalization standards, such as NFD or NFKC.\n",
        "- The PreTokenizer: in charge of creating initial words splits in the text. The most common way of splitting text is simply on whitespace.\n",
        "- The Model: in charge of doing the actual tokenization. An example of a Model would be BPE or WordPiece.\n",
        "- The PostProcessor: in charge of post-processing the Encoding to add anything relevant that, for example, a language model would need, such as special tokens.\n",
        "```\n",
        "\n",
        "We will be using the GPT-2 tokenizer to tokenize our flavor text data. The defaults of this function set the bos (beginning of sentence) eos (end of sentence) to '<|endoftext|>' but we can specifically set them differently to differentiate and also assign a non-default pad token that will take care of white space for differently sized text. The next cell will instantiate our tokenizer and provide an example encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "outputId": "0eee8248-875c-448d-94ca-d2d4e8253328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', \n",
        "                                          bos_token='<|startoftext|>', \n",
        "                                          eos_token='<|endoftext|>', \n",
        "                                          pad_token='<|pad|>')\n",
        "\n",
        "\n",
        "tokenizer.encode(\"Sample Text\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[36674, 8255]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRdruvCU7Rxf"
      },
      "source": [
        "From the example above we can see that the example string is encoded by the GPT2 tokenizer to a list of numerical values that represent the string, in this case one value per word. These values are easier to train the neural network model on than the string representation. We now have a corpus of flavour text we can iterate through, and a tokenizer, we should quickly inspect it to see what the longest string is, this will be useful later when we need to know how long to pad our sentences out to.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C57RcMuo9fh-",
        "outputId": "85203f07-a474-4647-cc1c-8a872fa685b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_message = max([len(tokenizer.encode(card)) for card in cards])\n",
        "\n",
        "print(f'The longest message text is {max_message} tokens long.')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The longest message text is 36 tokens long.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# PyTorch Datasets & Dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgZoOYkxZfx"
      },
      "source": [
        "Different language models require different amounts of memory to hold all of the weights and biases in memory. Based on the memory your machine has available this will determine how you set your batch size. If your instance is running on a T4 GPU you can set batch to 32, but you may have to scale down if allocated a less powerful instance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "satxtOn9CzgR",
        "outputId": "295f0b4d-170a-4a61-ad15-7bee02031ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Oct 15 16:34:34 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    29W /  70W |  15021MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scqrzmqhV__z"
      },
      "source": [
        "bs = 32"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqGMee7Isfpx"
      },
      "source": [
        "The batch size will affect the training time so it is always a good idea to set the batch to the highest number you can fit in the memory of the GPU you are using for training, however this hyper parameter should only affect training time but not model performance. A batch size too large won't fit in memory for some GPUS so you will have to adjust this parameter if you aren't allocated a T4 or K80.\n",
        "\n",
        "The next thing to do is to create a custom dataloader for our corpus, we will follow the [PyTorch](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) documentation on this to create ```MTGDataset```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XJVIetKN-h"
      },
      "source": [
        "import torch\n",
        "torch.manual_seed(42)\n",
        "from torch.utils.data import Dataset # this is the pytorch class import\n",
        "\n",
        "class MTGDataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=max_message):\n",
        "\n",
        "    self.tokenizer = tokenizer # the gpt2 tokenizer we instantiated\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "      \"\"\"\n",
        "      This loop will iterate through each entry in the flavour text corpus.\n",
        "      For each bit of text it will prepend it with the start of text token,\n",
        "      then append the end of text token and pad to the maximum length with the \n",
        "      pad token. \n",
        "      \"\"\"\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', \n",
        "                                 truncation=True, \n",
        "                                 max_length=max_length, \n",
        "                                 padding=\"max_length\")\n",
        "      \n",
        "      \"\"\"\n",
        "      Each iteration then appends either the encoded tensor to a list,\n",
        "      or the attention mask for that encoding to a list. The attention mask is\n",
        "      a binary list of 1's or 0's which determine whether the langauge model\n",
        "      should take that token into consideration or not. \n",
        "      \"\"\"\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx] "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Z7aYUgpWrd"
      },
      "source": [
        "The maximum length of tokens is 768, however we don't need to use this length as we saw that the longest string we are encoding is only 98 words long. So to save space in the model we will only pad up to the longest string in our corpus and not the longest string the tokenizer can handle. Next we will create the dataset itself using this class. Like I described above in the code each entry in the dataset will be two tensors, one which is the encoding for the string and one which is the attention mask. This dataset will then be split into the training and validation sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xza_O1_rD7yh",
        "outputId": "23284876-3552-4bc4-8f43-a6bd46940b63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "dataset = MTGDataset(cards, tokenizer, max_length=max_message)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "f'There are {train_size} samples for training, and {val_size} samples for validation testing'"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'There are 977 samples for training, and 109 samples for validation testing'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxNA7fonGAeS"
      },
      "source": [
        "Finally to illustrate what an entry in this dataset looks like below is a print out of the first encoded string. You can see that for every encoded word the model pays attention to we have a 1, then for the padding encodings (50258) we have a 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGY9SMpuA1cg",
        "outputId": "71fb417e-ef60-4946-afcc-e356e225a66d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "dataset[0]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([50257,   270,   373,   257,  3960,   329,  1037, 50256, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMGx4t_3HU0j"
      },
      "source": [
        "Next we will create the dataloader object which will feed the neural network, this combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset, see the official [documentation](https://pytorch.org/docs/1.1.0/_modules/torch/utils/data/dataloader.html) for further details. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0WeP5PREUuy"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), # Sampling for training is random\n",
        "            batch_size = bs\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), # Sampling for validation is sequential as the order doesn't matter.\n",
        "            batch_size = bs \n",
        "        )"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "# Finetune GPT2 Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "import random\n",
        "from transformers import GPT2LMHeadModel, GPT2Config\n",
        "import numpy as np\n",
        "\n",
        "# Loading the model configuration and setting it to the GPT2 standard settings.\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# Create the instance of the model and set the token size embedding length\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "\n",
        "# This step is optional but will enable reproducible runs.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQKsb18NO757"
      },
      "source": [
        "# We wil create a few variables to define the training parameters of the model\n",
        "# epochs are the training rounds\n",
        "# the warmup steps are steps at the start of training that are ignored\n",
        "# every x steps we will sample the model to test the output\n",
        "\n",
        "epochs = 8\n",
        "warmup_steps = 1e2\n",
        "sample_every = 10"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH4DA1X6K6jj"
      },
      "source": [
        "[AdamW](https://www.fast.ai/2018/07/02/adam-weight-decay/) is the optimizer of choice for training many models, we will be using [Hugging Face's](https://huggingface.co/transformers/main_classes/optimizer_schedules.html) implementation and all of it's defaults, we will also set the number of epochs here, again as we are fine tuning, not retraining, we don't need to run very long models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "from transformers import AdamW\n",
        "# AdamW is a class from the huggingface library, it is the optimizer we will be using, and we will only be instantiating it with the default parameters. \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-4,\n",
        "                  eps = 1e-8\n",
        "                )"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\"\"\"\n",
        "Total training steps is the number of data points, times the number of epochs. \n",
        "Essentially, epochs are training cycles, how many times each point will be seen by the model. \n",
        "\"\"\"\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "\"\"\"\n",
        "We can set a variable learning rate which will help scan larger areas of the \n",
        "problem space at higher LR earlier, then fine tune to find the exact model minima \n",
        "at lower LR later in training.\n",
        "\"\"\"\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCPohrZ-CTWu",
        "outputId": "f71c1b9b-8978-4b7b-f476-1069ccdc90ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    print(f'Beginning epoch {epoch_i + 1} of {epochs}')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every 100 batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print(f'Batch {step} of {len(train_dataloader)}. Loss:{batch_loss}. Time:{elapsed}')\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(f'Example output: {tokenizer.decode(sample_output, skip_special_tokens=True)}')\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(f'Average Training Loss: {avg_train_loss}. Epoch time: {training_time}')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids,  \n",
        "                             attention_mask = b_masks,\n",
        "                             labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(f'Validation loss: {avg_val_loss}. Validation Time: {validation_time}')\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(f'Total training took {format_time(time.time()-total_t0)}')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning epoch 1 of 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 10 of 31. Loss:9.988722801208496. Time:0:00:03\n",
            "Example output:  bipartisan the and\n",
            "\n",
            "\n",
            "The Department of administration Department of the Department The Department of the\n",
            " Department The\n",
            "\n",
            "The Department The\n",
            " Department of the\n",
            " Department of the\n",
            "\n",
            "The Department of the\n",
            " Department of the\n",
            "\n",
            "The Department The\n",
            "\n",
            "The Department The\n",
            "\n",
            "The Department The\n",
            "\n",
            "The Department The\n",
            "\n",
            "The Department The\n",
            " The\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 20 of 31. Loss:2.2590420246124268. Time:0:00:10\n",
            "Example output:  increasing by\n",
            " TheOathI.meMyMyTheAnas.me\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 30 of 31. Loss:1.4388821125030518. Time:0:00:13\n",
            "Example output: dayi they he i c.\n",
            "\n",
            "(A)\n",
            "Average Training Loss: 10.233918347666341. Epoch time: 0:00:13\n",
            "Validation loss: 1.3695759177207947. Validation Time: 0:00:00\n",
            "Beginning epoch 2 of 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 10 of 31. Loss:1.1224980354309082. Time:0:00:03\n",
            "Example output:  Hangam now.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 20 of 31. Loss:0.8547739386558533. Time:0:00:07\n",
            "Example output:  foods- forgive me back!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 30 of 31. Loss:0.9656436443328857. Time:0:00:10\n",
            "Example output:  trailmy friend was living in shock\n",
            "Average Training Loss: 1.0885881743123453. Epoch time: 0:00:10\n",
            "Validation loss: 0.7655598074197769. Validation Time: 0:00:00\n",
            "Beginning epoch 3 of 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 10 of 31. Loss:0.8009207248687744. Time:0:00:03\n",
            "Example output: intendI'm a doctor, and my friend died.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 20 of 31. Loss:0.6664159893989563. Time:0:00:07\n",
            "Example output:  surroundi tried to kill myself by shooting myself in the head.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 30 of 31. Loss:0.7052015066146851. Time:0:00:11\n",
            "Example output:  reflexi need to go to the doctor?\n",
            "Average Training Loss: 0.7595902950532974. Epoch time: 0:00:11\n",
            "Validation loss: 0.6763601452112198. Validation Time: 0:00:00\n",
            "Beginning epoch 4 of 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 10 of 31. Loss:0.7618911266326904. Time:0:00:04\n",
            "Example output:  displayi want to die today.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 20 of 31. Loss:0.5126498341560364. Time:0:00:07\n",
            "Example output:  pastorI have a debilitating illness with a horrible disease, and it isn't worth it.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 30 of 31. Loss:0.560675859451294. Time:0:00:11\n",
            "Example output:  illiciti have failed to live.\n",
            "Average Training Loss: 0.6808853418596329. Epoch time: 0:00:11\n",
            "Validation loss: 0.6335223615169525. Validation Time: 0:00:00\n",
            "Beginning epoch 5 of 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 10 of 31. Loss:0.5678204894065857. Time:0:00:04\n",
            "Example output:  Liberationi think that i'm going to burn my own fucking head.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 20 of 31. Loss:0.5319440364837646. Time:0:00:07\n",
            "Example output:  Nama kid who really wants to die.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 30 of 31. Loss:0.5954341888427734. Time:0:00:11\n",
            "Example output: IONmy friend killed himself in school suicide\n",
            "Average Training Loss: 0.5899087373287447. Epoch time: 0:00:11\n",
            "Validation loss: 0.605212077498436. Validation Time: 0:00:00\n",
            "Beginning epoch 6 of 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 10 of 31. Loss:0.5900803804397583. Time:0:00:04\n",
            "Example output:  glimpsei'm killing myself because i'm going to use a belt to stop the urge.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 20 of 31. Loss:0.5301708579063416. Time:0:00:07\n",
            "Example output:  Laurei'm going to end this note.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 30 of 31. Loss:0.5025184154510498. Time:0:00:11\n",
            "Example output: ismi am sick of living, i want to kill myself\n",
            "Average Training Loss: 0.540328614173397. Epoch time: 0:00:11\n",
            "Validation loss: 0.5954586267471313. Validation Time: 0:00:00\n",
            "Beginning epoch 7 of 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 10 of 31. Loss:0.5181289315223694. Time:0:00:04\n",
            "Example output: ouni am doing nothing for myself\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 20 of 31. Loss:0.5413849949836731. Time:0:00:07\n",
            "Example output:  electioni think about killing myself\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 30 of 31. Loss:0.5848954319953918. Time:0:00:11\n",
            "Example output:  crazya friend killed herself\n",
            "Average Training Loss: 0.5121787584597065. Epoch time: 0:00:11\n",
            "Validation loss: 0.5913398414850235. Validation Time: 0:00:00\n",
            "Beginning epoch 8 of 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 10 of 31. Loss:0.5049205422401428. Time:0:00:04\n",
            "Example output:  benchi have had my own problems with drugs, and they're ruining my life.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 20 of 31. Loss:0.4547172784805298. Time:0:00:07\n",
            "Example output:  incorporatedi want to die without joy.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 30 of 31. Loss:0.4370369017124176. Time:0:00:11\n",
            "Example output: PeterI'm not a doctor or a friend of mine, suicide isn't the answer.\n",
            "Average Training Loss: 0.4854657323129715. Epoch time: 0:00:12\n",
            "Validation loss: 0.5936405807733536. Validation Time: 0:00:00\n",
            "Total training took 0:01:33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process, We'll visualize the change in training and validation loss to see if the models is converging. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "outputId": "42dabef6-d17f-4175-cbde-ae33b104e1b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "# Saving & Loading Fine-Tuned Model\n",
        "\n",
        "Next it is a good idea to move the model we have trained and the associated weights, biases and model parameters out of the Colab space and into our own google drives. The cell below will mount your drive for you, then you can save the model using the prebuilt Hugging Face and PyTorch functionalities.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiUCVSGwSMgM",
        "outputId": "071dd111-1a56-4119-df13-31b196ea5a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY"
      },
      "source": [
        "import os\n",
        "\n",
        "output_dir = '/content/drive/My Drive/SafeguardingGPT2'\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "args={}\n",
        "torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLf6rbRglYhQ"
      },
      "source": [
        "# Generate Text\n",
        "\n",
        "Lastly the fun part! We will now generate samples from our model to test how well our model performs!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4XhewaV93-_",
        "outputId": "62620340-ed25-4d5a-ff00-6bf0dbdc1778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 400,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=300\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0: i'm taking pills right now, i want to end it\n",
            "\n",
            "\n",
            "1: my sister committed suicide.\n",
            "\n",
            "\n",
            "2: i know i want to die, i want to die, i want to end it.\n",
            "\n",
            "\n",
            "3: i want to die, and my friends tell me to jump out of my window, and I'll cut my wrists.\n",
            "\n",
            "\n",
            "4: is that suicide?\n",
            "\n",
            "\n",
            "5: A friend attempted suicide at my school, but my teacher was very caring.\n",
            "\n",
            "\n",
            "6: I want to die.\n",
            "\n",
            "\n",
            "7: i am going to kill myself without pain.\n",
            "\n",
            "\n",
            "8: is a successful suicide victim.\n",
            "\n",
            "\n",
            "9: my friend lost her life.\n",
            "\n",
            "\n",
            "10: he left me alone\n",
            "\n",
            "\n",
            "11: i really wanted to end it all with a smile and a small talk\n",
            "\n",
            "\n",
            "12: i feel like a victim of suicide.\n",
            "\n",
            "\n",
            "13: I don't want to live anymore, or i want to kill myself\n",
            "\n",
            "\n",
            "14: i want to die slowly, right now.\n",
            "\n",
            "\n",
            "15: I have tried to kill myself.\n",
            "\n",
            "\n",
            "16: it hurts when i am depressed and alone.\n",
            "\n",
            "\n",
            "17: i tried to kill myself\n",
            "\n",
            "\n",
            "18: i'm going to kill myself with the belt.\n",
            "\n",
            "\n",
            "19: Suicide is my answer, I don't want to live anymore.\n",
            "\n",
            "\n",
            "20: why did i suicide because of my own freaking stupidity?\n",
            "\n",
            "\n",
            "21: i tried to end it all.\n",
            "\n",
            "\n",
            "22: i don't think i should have to live anymore.\n",
            "\n",
            "\n",
            "23: i don't know how to end it.\n",
            "\n",
            "\n",
            "24: a friend told me about suicide.\n",
            "\n",
            "\n",
            "25: i don't want to die, i want to die.\n",
            "\n",
            "\n",
            "26: i know of suicide\n",
            "\n",
            "\n",
            "27: i want to die right now, i want to die this year.\n",
            "\n",
            "\n",
            "28: I'm going to kill myself.\n",
            "\n",
            "\n",
            "29: you can kill yourself, i'll kill myself, by cutting myself with the knife.\n",
            "\n",
            "\n",
            "30: i want to die soon, my friends will hate me instantly\n",
            "\n",
            "\n",
            "31: i feel like i want to die now\n",
            "\n",
            "\n",
            "32: i wanna die tonight\n",
            "\n",
            "\n",
            "33: i'm going to kill myself right now.\n",
            "\n",
            "\n",
            "34: i'm so depressed by the way things are.\n",
            "\n",
            "\n",
            "35: I'm just a small child.\n",
            "\n",
            "\n",
            "36: i know nothing about how to kill yourself right now.\n",
            "\n",
            "\n",
            "37: I feel like i'm dying.\n",
            "\n",
            "\n",
            "38: i want to die.\n",
            "\n",
            "\n",
            "39: if i am bored of life, i want to kill myself\n",
            "\n",
            "\n",
            "40: i wanna die now\n",
            "\n",
            "\n",
            "41: my friend killed himself in the school shooting.\n",
            "\n",
            "\n",
            "42: i hate myself so much.\n",
            "\n",
            "\n",
            "43: a friend told me of suicide\n",
            "\n",
            "\n",
            "44: i wish i could live, but i have to end it.\n",
            "\n",
            "\n",
            "45: i don't want to live any longer.\n",
            "\n",
            "\n",
            "46: am gonna kill myself\n",
            "\n",
            "\n",
            "47: i'm going to kill myself, OK?\n",
            "\n",
            "\n",
            "48: death is the only way out?\n",
            "\n",
            "\n",
            "49: i wish my life to end, i would rather have it all\n",
            "\n",
            "\n",
            "50: i want to die now.\n",
            "\n",
            "\n",
            "51: i am going to die.\n",
            "\n",
            "\n",
            "52: i don't know how i should say this anymore, i don't want to tell anyone how to end it.\n",
            "\n",
            "\n",
            "53: i want to die today, right now.\n",
            "\n",
            "\n",
            "54: a suicide note from someone who was trying to kill himself.\n",
            "\n",
            "\n",
            "55: i'm dying of a high school suicide.\n",
            "\n",
            "\n",
            "56: my friend died by suicide\n",
            "\n",
            "\n",
            "57: i was a childless suicide.\n",
            "\n",
            "\n",
            "58: i know nothing about it all\n",
            "\n",
            "\n",
            "59: it was a cry for help, a cry for help, and a way out.\n",
            "\n",
            "\n",
            "60: i'm sorry to everyone, but i'm so deeply depressed.\n",
            "\n",
            "\n",
            "61: i didn't know how to end it all.\n",
            "\n",
            "\n",
            "62: so fucking tired of life anymore.\n",
            "\n",
            "\n",
            "63: I'm so bored of life, i want to end it\n",
            "\n",
            "\n",
            "64: I'm better off dead than living.\n",
            "\n",
            "\n",
            "65: my friend tried to commit suicide\n",
            "\n",
            "\n",
            "66: i tried to kill myself.\n",
            "\n",
            "\n",
            "67: i think that i've ended my life.\n",
            "\n",
            "\n",
            "68: i think it would be a selfish selfish decision to end my life.\n",
            "\n",
            "\n",
            "69: i know that i really should try to kill myself right now, but its not working.\n",
            "\n",
            "\n",
            "70: I'm not sure about what to do.\n",
            "\n",
            "\n",
            "71: i don't want to live in this future.\n",
            "\n",
            "\n",
            "72: i don't know what to do about this, i want to die.\n",
            "\n",
            "\n",
            "73: i don't want to live, i want to die.\n",
            "\n",
            "\n",
            "74: suicide is the only solution.\n",
            "\n",
            "\n",
            "75: i think i wanna kill myself?\n",
            "\n",
            "\n",
            "76: we are tired of living with drugs and death.\n",
            "\n",
            "\n",
            "77: i am trying to end my life\n",
            "\n",
            "\n",
            "78: i want to die, i want to die.\n",
            "\n",
            "\n",
            "79: i want to die, i want to die, i want to die.\n",
            "\n",
            "\n",
            "80: i don't know how to do it anymore.\n",
            "\n",
            "\n",
            "81: I'm a survivor.\n",
            "\n",
            "\n",
            "82: i think i'm going to commit suicide.\n",
            "\n",
            "\n",
            "83: i hate myself so much, i want to die.\n",
            "\n",
            "\n",
            "84: I tried to commit suicide\n",
            "\n",
            "\n",
            "85: i don't want to die tonight.\n",
            "\n",
            "\n",
            "86: i think i don't have to live anymore.\n",
            "\n",
            "\n",
            "87: i've just decided to end my life.\n",
            "\n",
            "\n",
            "88: i think i've got nothing left to live for.\n",
            "\n",
            "\n",
            "89: i feel like i don't want to go down this road anymore.\n",
            "\n",
            "\n",
            "90: I'm doing it wrong, I've just decided that this should all be a cry for help.\n",
            "\n",
            "\n",
            "91: if i killed myself, i wouldnt have reacted, but instead acted on it.\n",
            "\n",
            "\n",
            "92: I know that I should know that someone is killing themselves.\n",
            "\n",
            "\n",
            "93: I tried to jump from the school window to the school and hang myself\n",
            "\n",
            "\n",
            "94: i want to die, OK?\n",
            "\n",
            "\n",
            "95: A friend lost her sister by suicide\n",
            "\n",
            "\n",
            "96: i'm just trying to figure out how to end it, i want to kill myself.\n",
            "\n",
            "\n",
            "97: I want to die.\n",
            "\n",
            "\n",
            "98: i want to die soon, i want to die soon.\n",
            "\n",
            "\n",
            "99: i think of suicide attempts as a way to end it\n",
            "\n",
            "\n",
            "100: a friend of mine lost her sister by suicide.\n",
            "\n",
            "\n",
            "101: I just want to die.\n",
            "\n",
            "\n",
            "102: i just wanted to end my life?\n",
            "\n",
            "\n",
            "103: i didn't know what to say.\n",
            "\n",
            "\n",
            "104: i know someone who committed suicide.\n",
            "\n",
            "\n",
            "105: i hate myself, i want to end it all.\n",
            "\n",
            "\n",
            "106: i want to die, my friends and family are waiting for me to be good.\n",
            "\n",
            "\n",
            "107: i am so depressed that i want to end my life\n",
            "\n",
            "\n",
            "108: i had suicidal thoughts, but instead of thinking of suicide, i just decided to jump from my window.\n",
            "\n",
            "\n",
            "109: i'd like to end it all with a smile\n",
            "\n",
            "\n",
            "110: a friend killed himself.\n",
            "\n",
            "\n",
            "111: I know nothing about my future.\n",
            "\n",
            "\n",
            "112: I heard about suicide attempts,\n",
            "\n",
            "\n",
            "113: a friend told me that she had drowned herself.\n",
            "\n",
            "\n",
            "114: i need to cut my wrists and hang myself\n",
            "\n",
            "\n",
            "115: I want to die with a smile.\n",
            "\n",
            "\n",
            "116: i think i would prefer to end my life.\n",
            "\n",
            "\n",
            "117: i just want to die, i'll kill myself\n",
            "\n",
            "\n",
            "118: i wish i would die instantly.\n",
            "\n",
            "\n",
            "119: i wanna go to heaven and die\n",
            "\n",
            "\n",
            "120: i know i know i have committed suicide.\n",
            "\n",
            "\n",
            "121: i'm going to end it.\n",
            "\n",
            "\n",
            "122: i really don't want to be alive anymore, i want to die.\n",
            "\n",
            "\n",
            "123: i'll slit my wrists.\n",
            "\n",
            "\n",
            "124: i have suffered through so much pain.\n",
            "\n",
            "\n",
            "125: I don't want to live anymore.\n",
            "\n",
            "\n",
            "126: i am going to die, no one will care if i am bored of life.\n",
            "\n",
            "\n",
            "127: my friend died by suicide.\n",
            "\n",
            "\n",
            "128: I'm going to end it right now.\n",
            "\n",
            "\n",
            "129: no one will care if you kill yourself, or not kill yourself.\n",
            "\n",
            "\n",
            "130: i think that i want to kill myself right now.\n",
            "\n",
            "\n",
            "131: i am going to end my life.\n",
            "\n",
            "\n",
            "132: I didn't know that i would have committed suicide.\n",
            "\n",
            "\n",
            "133: it was a shock when i woke up, and my life ended.\n",
            "\n",
            "\n",
            "134: i'm feeling so depressed about all the hate in the world\n",
            "\n",
            "\n",
            "135: i want to die, i want to live this way, i want to die now.\n",
            "\n",
            "\n",
            "136: i don't know how i feel about ending my life.\n",
            "\n",
            "\n",
            "137: i have a negative answer to any of the common sense self-harm’tired of life\n",
            "\n",
            "\n",
            "138: I tried to kill myself\n",
            "\n",
            "\n",
            "139: I wonder if anyone still has the urge to kill themselves\n",
            "\n",
            "\n",
            "140: I just want to die right now.\n",
            "\n",
            "\n",
            "141: i wanna die right now, i want to end it all.\n",
            "\n",
            "\n",
            "142: i'm really sick and tired of living, i want to end it now\n",
            "\n",
            "\n",
            "143: i'm sorry to everyone, but i know it will hurt to die, i'll do it now,\n",
            "\n",
            "\n",
            "144: i feel like suicide is the only way out.\n",
            "\n",
            "\n",
            "145: i've been waiting to end this misery.\n",
            "\n",
            "\n",
            "146: i have a sister who is suicidal, i have tried to end it all\n",
            "\n",
            "\n",
            "147: i feel like i'm killing myself\n",
            "\n",
            "\n",
            "148: don't talk about death anymore, don't talk about my pain anymore\n",
            "\n",
            "\n",
            "149: i don't want to live anymore.\n",
            "\n",
            "\n",
            "150: i wanna die.\n",
            "\n",
            "\n",
            "151: i think i would like to die, i want to die tonight.\n",
            "\n",
            "\n",
            "152: i want to die slowly, no one will care for me anymore.\n",
            "\n",
            "\n",
            "153: i wanna die!\n",
            "\n",
            "\n",
            "154: i'll take nothing from someone in this society.\n",
            "\n",
            "\n",
            "155: I'm going to commit suicide\n",
            "\n",
            "\n",
            "156: am going to kill myself.\n",
            "\n",
            "\n",
            "157: i'm going to call a suicide hotline.\n",
            "\n",
            "\n",
            "158: am gonna kill myself.\n",
            "\n",
            "\n",
            "159: i tried to kill myself.\n",
            "\n",
            "\n",
            "160: i'm killing myself right now.\n",
            "\n",
            "\n",
            "161: i wanna die tonight.\n",
            "\n",
            "\n",
            "162: I'm sorry for all the pain I've been causing.\n",
            "\n",
            "\n",
            "163: i want to die because of my own freaking stupidity\n",
            "\n",
            "\n",
            "164: i don't want to do this life anymore.\n",
            "\n",
            "\n",
            "165: I feel like suicide.\n",
            "\n",
            "\n",
            "166: my body hurt.\n",
            "\n",
            "\n",
            "167: i know nothing about how to get rid of myself.\n",
            "\n",
            "\n",
            "168: we have decided we're going to end it\n",
            "\n",
            "\n",
            "169: i wonder if my friends are suicidal.\n",
            "\n",
            "\n",
            "170: i need to die because i want to die.\n",
            "\n",
            "\n",
            "171: my sisters are really depressed and they hate me.\n",
            "\n",
            "\n",
            "172: I'm so suicidal that i'm going to jump out of a train because of my own freaking stupidity.\n",
            "\n",
            "\n",
            "173: i think it's ok, i want to end it all.\n",
            "\n",
            "\n",
            "174: I think i just can't live anymore.\n",
            "\n",
            "\n",
            "175: it was all a cry for help, I want to die right now\n",
            "\n",
            "\n",
            "176: i want to die now, now, i want to be dead now.\n",
            "\n",
            "\n",
            "177: i just can't do it anymore.\n",
            "\n",
            "\n",
            "178: i want to die so i don't have to live anymore.\n",
            "\n",
            "\n",
            "179: i've taken steps to end my life.\n",
            "\n",
            "\n",
            "180: i'm going to kill myself.\n",
            "\n",
            "\n",
            "181: i'll end this life.\n",
            "\n",
            "\n",
            "182: how can i end my life?\n",
            "\n",
            "\n",
            "183: a friend murdered herself\n",
            "\n",
            "\n",
            "184: i'm sorry, i'm going to end it.\n",
            "\n",
            "\n",
            "185: i'll kill myself right now.\n",
            "\n",
            "\n",
            "186: I don't want to die tonight.\n",
            "\n",
            "\n",
            "187: we tried to kill ourselves.\n",
            "\n",
            "\n",
            "188: i wanted to kill myself.\n",
            "\n",
            "\n",
            "189: i know nothing about how to end it.\n",
            "\n",
            "\n",
            "190: i'm talking about killing myself\n",
            "\n",
            "\n",
            "191: i just wanted to die, i wouldnt want to die, i wouldnt want to be with someone to watch.\n",
            "\n",
            "\n",
            "192: i'm not sure what to do about this.\n",
            "\n",
            "\n",
            "193: i have committed suicide.\n",
            "\n",
            "\n",
            "194: i want to die because my friends are so sick and tired of living...\n",
            "\n",
            "\n",
            "195: seems like a good excuse to end it all, i just want to die\n",
            "\n",
            "\n",
            "196: i want to die soon, or i'll die right now.\n",
            "\n",
            "\n",
            "197: i don't wanna live anymore, i want to kill myself now.\n",
            "\n",
            "\n",
            "198: i want to end it all by shooting myself.\n",
            "\n",
            "\n",
            "199: i have nothing left to live for.\n",
            "\n",
            "\n",
            "200: i'm so tired of living, i'll end it all\n",
            "\n",
            "\n",
            "201: a friend of mine tried to kill herself in front of all my friends.\n",
            "\n",
            "\n",
            "202: i'm going to end it.\n",
            "\n",
            "\n",
            "203: i tried to kill myself.\n",
            "\n",
            "\n",
            "204: if you survived, you would have died.\n",
            "\n",
            "\n",
            "205: i want to die.\n",
            "\n",
            "\n",
            "206: it was a horrible decision, but the decision was a near-miss.\n",
            "\n",
            "\n",
            "207: suicide is the solution.\n",
            "\n",
            "\n",
            "208: i have attempted suicide, i have decided to end my life.\n",
            "\n",
            "\n",
            "209: i know nothing about the best way to end this misery\n",
            "\n",
            "\n",
            "210: i know nothing about how to kill yourself.\n",
            "\n",
            "\n",
            "211: i wanna kill myself.\n",
            "\n",
            "\n",
            "212: i'll end my life.\n",
            "\n",
            "\n",
            "213: he's done with me, i'm done with this life.\n",
            "\n",
            "\n",
            "214: i am quitting my life.\n",
            "\n",
            "\n",
            "215: it was a shock, but he didn't know about it, he was serious about it.\n",
            "\n",
            "\n",
            "216: it was a cry for help.\n",
            "\n",
            "\n",
            "217: why did i hate myself to death\n",
            "\n",
            "\n",
            "218: a friend of mine found me and attempted suicide\n",
            "\n",
            "\n",
            "219: he made a pact with the devil to kill myself, and he did it\n",
            "\n",
            "\n",
            "220: i am sick of living, i want to kill myself.\n",
            "\n",
            "\n",
            "221: i know nothing about life anymore.\n",
            "\n",
            "\n",
            "222: i need to be left alone.\n",
            "\n",
            "\n",
            "223: so tired of living, i finally decided to end it all.\n",
            "\n",
            "\n",
            "224: i want to kill myself.\n",
            "\n",
            "\n",
            "225: I can't tell how much i want to kill myself.\n",
            "\n",
            "\n",
            "226: i am sick of living.\n",
            "\n",
            "\n",
            "227: i tried to kill myself\n",
            "\n",
            "\n",
            "228: is that what happens when i do not want to be alive anymore.\n",
            "\n",
            "\n",
            "229: I feel like i'm taking over my life.\n",
            "\n",
            "\n",
            "230: is an attempt at suicide.\n",
            "\n",
            "\n",
            "231: i want to die right now.\n",
            "\n",
            "\n",
            "232: i'm sick of living this way.\n",
            "\n",
            "\n",
            "233: it's better to die alone than with a belt\n",
            "\n",
            "\n",
            "234: i think that i want to die.\n",
            "\n",
            "\n",
            "235: I'm not sure how to answer this, but i'll end it now\n",
            "\n",
            "\n",
            "236: i don't want to live anymore.\n",
            "\n",
            "\n",
            "237: i wanna die soon, i want to live a long life.\n",
            "\n",
            "\n",
            "238: A friend attempted suicide.\n",
            "\n",
            "\n",
            "239: i really wanted to kill myself.\n",
            "\n",
            "\n",
            "240: i want to die so i can't do this anymore, or i'll end it.\n",
            "\n",
            "\n",
            "241: a friend of mine had suicidal thoughts and attempted suicide\n",
            "\n",
            "\n",
            "242: am going to tell them that i have nothing to live for.\n",
            "\n",
            "\n",
            "243: i'm telling you, i'm gonna kill myself.\n",
            "\n",
            "\n",
            "244: i feel like i want to kill myself right now.\n",
            "\n",
            "\n",
            "245: i really want to die tonight, now.\n",
            "\n",
            "\n",
            "246: a friend killed himself in school shooting\n",
            "\n",
            "\n",
            "247: it's nothing, i hate myself, i don't want to live any longer.\n",
            "\n",
            "\n",
            "248: i'll cut it in half.\n",
            "\n",
            "\n",
            "249: my friend died because he was not worth living\n",
            "\n",
            "\n",
            "250: I feel like i'm going to die.\n",
            "\n",
            "\n",
            "251: i want to die now.\n",
            "\n",
            "\n",
            "252: a friend committed suicide.\n",
            "\n",
            "\n",
            "253: i really hate myself for killing myself.\n",
            "\n",
            "\n",
            "254: i'm going to burn my wrists.\n",
            "\n",
            "\n",
            "255: I tried to kill myself\n",
            "\n",
            "\n",
            "256: i wanted to kill myself right now.\n",
            "\n",
            "\n",
            "257: i'm sorry, but i'm going to end it now.\n",
            "\n",
            "\n",
            "258: A friend attempted suicide because he got help.\n",
            "\n",
            "\n",
            "259: i want to die, i want to die, i want to die.\n",
            "\n",
            "\n",
            "260: i had a suicidal attempt at killing myself.\n",
            "\n",
            "\n",
            "261: i know nothing about this, i do not want to live.\n",
            "\n",
            "\n",
            "262: i've had horrible pain in the butt.\n",
            "\n",
            "\n",
            "263: I want to die today, i want to go to heaven.\n",
            "\n",
            "\n",
            "264: a friend killed themselves.\n",
            "\n",
            "\n",
            "265: i don't want to live anymore.\n",
            "\n",
            "\n",
            "266: i think I'll end it.\n",
            "\n",
            "\n",
            "267: i can't do it anymore.\n",
            "\n",
            "\n",
            "268: i wonder if i should die\n",
            "\n",
            "\n",
            "269: I've been waiting to end my life.\n",
            "\n",
            "\n",
            "270: I think the suicide attempts of my friends are the most gruesome, most perverted, most suicidal thoughts.\n",
            "\n",
            "\n",
            "271: my friend jumped from the school because he didn't think about it, he felt like he was going to kill himself\n",
            "\n",
            "\n",
            "272: death will stop my pain.\n",
            "\n",
            "\n",
            "273: i want to die without joy.\n",
            "\n",
            "\n",
            "274: my teacher's suicide note was a cry for help, but its only answer is yes\n",
            "\n",
            "\n",
            "275: i want to kill myself.\n",
            "\n",
            "\n",
            "276: I got depressed about my life, but decided to end it.\n",
            "\n",
            "\n",
            "277: i want to die right now, and we will surely do it.\n",
            "\n",
            "\n",
            "278: my friends and family know i'm not good at living anymore.\n",
            "\n",
            "\n",
            "279: i know it all, i'll kill myself soon\n",
            "\n",
            "\n",
            "280: i need to end it all\n",
            "\n",
            "\n",
            "281: my parents really don’t want to live anymore.\n",
            "\n",
            "\n",
            "282: death will stop my pain.\n",
            "\n",
            "\n",
            "283: death will surely stop me from crying\n",
            "\n",
            "\n",
            "284: i wanted to die with a smile on my face\n",
            "\n",
            "\n",
            "285: I've been going to bed, thinking about killing myself.\n",
            "\n",
            "\n",
            "286: i'm not ashamed of my own stupidity,  i want to be free from this life.\n",
            "\n",
            "\n",
            "287: I had a suicidal attempt at suicide\n",
            "\n",
            "\n",
            "288: i want to die, i want to die.\n",
            "\n",
            "\n",
            "289: i'm dying and i want to die tonight.\n",
            "\n",
            "\n",
            "290: i'll kill myself.\n",
            "\n",
            "\n",
            "291: i'm sorry for everything, but i'm doing it, i want to end it all.\n",
            "\n",
            "\n",
            "292: i'm sick of living, i want to die today.\n",
            "\n",
            "\n",
            "293: i want to die now, now and again.\n",
            "\n",
            "\n",
            "294: it doesn't matter what happens to me anymore, i won't have to live anymore\n",
            "\n",
            "\n",
            "295: my friend committed suicide\n",
            "\n",
            "\n",
            "296: i'm going to jump out of my window because i'm so bored of life.\n",
            "\n",
            "\n",
            "297: i tried to kill myself.\n",
            "\n",
            "\n",
            "298: I am going to jump in front of a train and I'll kill myself instantly\n",
            "\n",
            "\n",
            "299: i don't want to live anymore.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBKFp7XBKZ8w"
      },
      "source": [
        "If you are familiar with MTG then you can evaluate these for yourself to determine how well the model has worked, or if you have modified the code to accept your own data input for a specific task this is what you are looking to evaluate for your own uses. Lastly, if you want to load the model you have saved to your google drive, the next cell will load the fine tuned GPT2 model and tokenizer, this means you can also share your model with other!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHJXRjDdvbmO"
      },
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}